{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "1630fb60-d24a-46a7-ad4e-2807b388964c",
    "_uuid": "aea9fb9bd8cd770862106299ee4e81f6061780d8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first_pron = ['I', \"I'm\",'me', 'my','mine', 'myself','we',\"we're\",'us','our','ours','ourselves']\n",
    "# second_pron = ['you',\"you're\",'your', 'yours', 'yourself','yourselves']\n",
    "# third_pron = ['he',\"he's\",'him','his','himself','she',\"she's\",'her','hers','herself',\\\n",
    "#                     'they',\"they're\",'them','their','theirs','themselves',\\\n",
    "#                     'it',\"it's\",'its','itself']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   type                                              posts\n",
      "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
      "1  ENTP  'I'm finding the lack of me in these posts ver...\n",
      "2  INTP  'Good one  _____   https://www.youtube.com/wat...\n",
      "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
      "4  ENTJ  'You're fired.|||That's another silly misconce...\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./mbti_1.csv')\n",
    "x = df.head()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_pron_pat = r\"(?i)\\b(I|me|my|mine|myself|we|us|our|ours|ourselves)\\b\"\n",
    "first_pron_num = 10\n",
    "second_pron_pat = r\"(?i)\\b(you|your|yours|yourself|yourselves)\\b\"\n",
    "second_pron_num = 5\n",
    "third_pron_pat = r\"(?i)\\b(he|him|his|himself|she|her|hers|herself|they|them|their|theirs|themselves|it|its|itself)\\b\"\n",
    "third_pron_num = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['1st_pron_count'] = df['posts'].str.count(pat=first_pron_pat)/first_pron_num\n",
    "df['2nd_pron_count'] = df['posts'].str.count(pat=second_pron_pat)/second_pron_num\n",
    "df['3rd_pron_count'] = df['posts'].str.count(pat=third_pron_pat)/third_pron_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentence_count'] = df['posts'].str.count(pat=r\"\\|\\|\\|\")+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>1st_pron_count</th>\n",
       "      <th>2nd_pron_count</th>\n",
       "      <th>3rd_pron_count</th>\n",
       "      <th>sentence_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "      <td>12.6</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.4375</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.6250</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "      <td>9.7</td>\n",
       "      <td>6.4</td>\n",
       "      <td>1.7500</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts  1st_pron_count  \\\n",
       "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...             2.4   \n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...            12.6   \n",
       "2  INTP  'Good one  _____   https://www.youtube.com/wat...             5.0   \n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...             9.7   \n",
       "4  ENTJ  'You're fired.|||That's another silly misconce...             5.1   \n",
       "\n",
       "   2nd_pron_count  3rd_pron_count  sentence_count  \n",
       "0             3.4          0.7500              50  \n",
       "1             6.6          2.4375              50  \n",
       "2             4.6          1.6250              50  \n",
       "3             6.4          1.7500              50  \n",
       "4             3.8          3.0000              50  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "ENFJ    0.240665\n",
       "ENFP    0.235781\n",
       "ENTJ    0.194438\n",
       "ENTP    0.194793\n",
       "ESFJ    0.248117\n",
       "ESFP    0.187946\n",
       "ESTJ    0.218584\n",
       "ESTP    0.196864\n",
       "INFJ    0.230801\n",
       "INFP    0.234112\n",
       "INTJ    0.199120\n",
       "INTP    0.202082\n",
       "ISFJ    0.237631\n",
       "ISFP    0.218515\n",
       "ISTJ    0.217331\n",
       "ISTP    0.199594\n",
       "dtype: float64"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['type'])['1st_pron_count'].sum()/df.groupby(['type'])['sentence_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "ENFJ    0.126120\n",
       "ENFP    0.121511\n",
       "ENTJ    0.135279\n",
       "ENTP    0.121140\n",
       "ESFJ    0.109514\n",
       "ESFP    0.104650\n",
       "ESTJ    0.117543\n",
       "ESTP    0.117039\n",
       "INFJ    0.120277\n",
       "INFP    0.106212\n",
       "INTJ    0.115805\n",
       "INTP    0.105737\n",
       "ISFJ    0.108607\n",
       "ISFP    0.099431\n",
       "ISTJ    0.111409\n",
       "ISTP    0.105758\n",
       "dtype: float64"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['type'])['2nd_pron_count'].sum()/df.groupby(['type'])['sentence_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "ENFJ    0.062305\n",
       "ENFP    0.058060\n",
       "ENTJ    0.055204\n",
       "ENTP    0.053607\n",
       "ESFJ    0.061354\n",
       "ESFP    0.050339\n",
       "ESTJ    0.055830\n",
       "ESTP    0.054675\n",
       "INFJ    0.057692\n",
       "INFP    0.054730\n",
       "INTJ    0.054274\n",
       "INTP    0.053994\n",
       "ISFJ    0.056482\n",
       "ISFP    0.053558\n",
       "ISTJ    0.055180\n",
       "ISTP    0.053529\n",
       "dtype: float64"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['type'])['3rd_pron_count'].sum()/df.groupby(['type'])['sentence_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
